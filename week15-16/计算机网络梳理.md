



# 计算机网络复习

本篇为我复习计算机网络的体系(虽然似乎也不是很成体系）梳理。

------

# 应用层：

## 从浏览器开始：

以书本的章节结构来复习实在太无聊了。

据说面试考计算机网络题喜欢问：当你在浏览器的导航栏输入一个 url 后会发生什么，越详细越好，所以我们复习也从这里开始。

![旅程的开始](https://picture.cry4o4n0tfound.cn/crywebsite/2025/05/url.png)

以本站为例，当我在浏览器导航栏敲下对应的 url 后，浏览器就开始工作了。

浏览器是一个应用，所以对应的协议都是应用层的，而对于 cry4o4n0tfound.cn 这个 url，它其实并不知道是什么含义，所有的域名（Domain Name）仅仅只是为了方便人类的记忆，域名的背后，是一段难记的 ip 地址。于是第一个接触到的应用层协议出现了--DNS。

------

## DNS(Domain Name System):

让我们用 wireshark 抓个包看一眼 dns 是什么样的。

![dns](https://picture.cry4o4n0tfound.cn/crywebsite/2025/05/dns.png)

可以看到我询问 tpstelemetry.tencent.com 的 ipv4 (A) 和 ipv6（AAAA) 地址，然后校园内的 dns 服务器返回了一些它询问的内容（很大概率是已经缓存在服务器的内容）。

前面的一串 A tpstelemetry.tencent.com A 113.240.75.252 .... 很明显是我查询对应的域名的实际 ip 地址，而后面的 NS ns-tel1.qq.com ... 则是提供实际查询响应的 Name Server 的 ip 地址。这里的 NS、A、AAAA 都是 dns 资源记录的类型，代表对应的域名的实际用途到底是干嘛的。

于是到了这里，我们需要了解 DNS 查询是怎样的以及 DNS 的记录到底是个什么东西了。

### DNS 查询：

dns 的查询分为迭代查询和递归查询。

#### 递归查询：

![递归查询](https://picture.cry4o4n0tfound.cn/crywebsite/2025/05/digui.png)

对于递归查询而言，dns 会层层问下去，先问根域 服务器. 然后再问顶级域名服务器，比如 .cn ，再然后就问到了你的权威域名服务器 wewerss.cry4o4n0tfound.cn 在哪里啊，比如本网站对应的 cloudflare 的那两台服务器。然后一次性返回回来。这是比较方便快捷便于缓存的。

系统性讲来就是这样：

1. **主机首先向其本地域名服务器进行递归查询。** （“帮我查查这个域名是啥 IP，查到了直接告诉我结果”）
2. 本地域名服务器收到递归查询的委托后，也采用递归查询的方式向某个根域名服务器查询。（“根，你帮我查查这个，查到了告诉我结果”）
3. 根域名服务器收到递归查询的委托后，也采用递归查询的方式向某个顶级域名服务器查询。（“顶级，你帮我查查这个，查到了告诉我结果”）
4. 顶级域名服务器收到递归查询的委托后，也采用递归查询的方式向某个权威域名服务器查询。（“权威，你就是管这个的，查查告诉我结果”）
5. 权威域名服务器将结果返回给顶级域名服务器，顶级返回给根，根返回给本地域名服务器，本地域名服务器最终将结果返回给主机。

**唯一需要注意的是，电脑上其实还有 host 文件，如果本机的 host 文件上有对应的映射，那么就可以直接访问了，最早最早的 GFW 可以靠这种方式绕过...** 浏览器也会有自己的 DNS 缓存。所以查询顺序一般是：浏览器缓存 -> 系统 hosts 文件 -> 本地域名服务器缓存 -> 递归/迭代查询。

#### 迭代查询：

![迭代查询](https://picture.cry4o4n0tfound.cn/crywebsite/2025/05/diedai.png)

迭代查询就是踢皮球，你说不知道，那我得去找下一个，而不是直接交给上面一层让它给你直接办好（是不是有点像政府行政？）。

系统性讲的话就是：

1. 主机首先向其本地域名服务器进行递归查询。（这一步通常不变，客户端总是想省事）
2. 本地域名服务器采用迭代查询，它先向某个根域名服务器查询。（“根，你知道 xxx.com 怎么走吗？”）
3. 根域名服务器告诉本地域名服务器：“我不知道 xxx.com，但我知道 .com 的服务器地址是 yyy.yyy.yyy.yyy，你去问它。”
4. 本地域名服务器向顶级域名服务器（.com 的服务器）进行迭代查询。（“.com ，你知道 xxx.com 怎么走吗？”）
5. 顶级域名服务器告诉本地域名服务器：“我不知道 xxx.com 的具体 IP，但我知道 xxx.com 的权威域名服务器地址是 zzz.zzz.zzz.zzz，你去问它。”
6. 本地域名服务器向权限域名服务器进行迭代查询。（“zzz.zzz.zzz.zzz 权威，xxx.com 的 IP 是多少？”）
7. 权限域名服务器告诉本地域名服务器所查询的域名的IP地址。（“xxx.com 的 IP 是 aaa.bbb.ccc.ddd”）
8. 本地域名服务器最后把查询的结果告诉主机。

需要注意的是，一般来讲我们本地的客户端（也就是手机电脑）是使用递归查询将请求传递给本地 dns 服务器的，因为上网的人基本不在乎到底是怎么上网的，自然不会在意 dns 查询的细节。而本地的 dns 服务器则是迭代查询，可以减轻权威域名服务器的负载压力，以免所有的都查询到它头上。

除此之外，递归查询也存在危险，相信一个 dns 服务器，并且递归查询，也就意味着它说什么你就信什么，这里会引起**DNS劫持**（返回一个假的IP地址，比如钓鱼网站）或者**DNS污染**（返回一个不存在或者错误的IP，让你访问不了真正的网站），从而导致电信诈骗等一系列不那么愉快的事情（这也是为什么国内云服务器基本不会开放 53 端口拿给你做 DNS 解析的原因）。

当然，也可以使用 DNS 解锁奈飞、closeai 等，这也是利用 dns 的特性，但这不在复习的讨论之中。

### DNS 记录：

dns 记录常用的就以下几种类型（至少我日常用到的就这些）

1. **A 记录 (Address Record)**:
   - 用途：将域名映射到 IPv4 地址。
   - 示例：比如 cry4o4n0tfound.cn 的子域名 bookmark.cry4o4n0tfound.cn、vaultwarden.cry4o4n0tfound.cn ，这些都映射了某个我服务器上的 ip 地址。 google.com A 172.217.160.142
2. **AAAA 记录 (Quad-A Record)**:
   - 用途：将域名映射到 IPv6 地址。
   - 示例：同上，只不过换成了 ipv6。 google.com AAAA 2404:6800:4005:812::200e
3. **NS 记录 (Name Server Record)**:
   - 用途：指定负责特定域或子域的权威名称服务器。
   - 示例：例如将域名托管到 cloudflare，cloudflare 会提供两个 NS 域名服务器，里面存储了你的域名的详细信息，也就意味着，当访问托管的这个域名，比如 cry4o4n0tfound.cn 时，你希望是以对应的域名服务器来做解析的，这个时候，这两个服务器就成了你域名的**权威名称服务器**。其余的查询最终会走到这两个服务器上，然后本地服务器缓存对应的内容，方便下次访问。 example.com. NS ns1.exampledns.com.
4. **CNAME 记录 (Canonical Name Record)**:
   - 用途：创建一个域名的别名，指向另一个域名（规范名称）。 CNAME 记录不能指向 IP 地址。
   - 示例：`www.example.com.` CNAME example.com. 表示` www.example.com` 是 example.com 的别名。 当用户访问` www.example.com `时，DNS 解析器会首先查找 example.com 的 A 记录或 AAAA 记录，然后返回对应的 IP 地址。
   - 重要限制: CNAME 记录不能与同一域名的其他记录（例如 A、AAAA、MX）共存。 例如，你不能同时拥有 example.com. A 192.0.2.1 和 example.com. CNAME otherdomain.com.。
   - **比如 cry4o4n0tfound.cn 就是依靠 CNAME 解析到一个 cloudflarepage 上的**
5. **MX 记录 (Mail Exchange Record)**:
   - 用途：指定负责接收域的电子邮件的邮件服务器。 MX 记录包含优先级信息，用于确定邮件服务器的顺序。
   - 示例：example.com. MX 10 mail.example.com.
     example.com. MX 20 backupmail.example.com.
   - 10 和 20 是优先级值，数字越小，优先级越高。 在这个例子中，mail.example.com 的优先级高于 backupmail.example.com。
   - mail.example.com 和 backupmail.example.com 是邮件服务器的主机名。 这些主机名需要有对应的 A 记录或 AAAA 记录，以指定邮件服务器的 IP 地址。

### DNS 报文：

![dns-data](https://picture.cry4o4n0tfound.cn/crywebsite/2025/05/dns-data.png)

- 前12个字节是**首部区域**，其中有几个字段。
  - 第一个字段（**标识符 Transaction ID**）是一个16比特的数，用于标识该查询。该标识符会被复制到对查询的回答报文中，以便让客户用它来匹配发送的请求和接收到的回答。（类似快递单号，发出去的请求和你收到的响应能对上号）
  - **标志字段 (Flags)** 中含有若干标志。
    - 1比特的 **“查询/回答” (QR)** 标志位指出报文是 **查询报文(0)** 还是 **回答报文(1)** 。
    - 4比特的 **Opcode** 字段，通常为0（标准查询）。
    - 1比特的 **“权威的” (AA)** 标志位将会被置在回答报文中，当某DNS服务器是所请求名字的权威DNS服务器时。
    - 1比特的 **Truncation (TC)** 标志，表示响应超过512字节（UDP限制），已被截断。
    - 如果客户在该DNS服务器没有某记录时，希望它执行**递归**查询，将设置1比特的 **“希望递归” (RD)** 标志位。
    - 如果该DNS服务器支持递归查询，则在回答报文中会对1比特的 **“递归可用” (RA)** 标志位置位。
    - 还有一些保留位和RCODE（响应码，比如0表示无差错，3表示域名不存在）。
  - 接下来是四个16位的计数器，分别表示问题数、回答数、权威记录数、附加记录数。
- 问题区域 (Questions)：包含着正在进行的查询信息。其中，该区域包括
  - 名字字段 (QNAME)，包含正在被查询的主机名字（例如` www.example.com`，会用特定格式编码）。
  - 类型字段 (QTYPE)，指出有关该名字的正被询问的问题类型，例如主机地址是与一个名字相关联（类型A）还是与某个名字的邮件服务器相关联（类型MX）。
  - 类别字段 (QCLASS)，通常是IN（表示互联网地址）。
- 在来自DNS服务器的回答中，**回答区域 (Answers)** 包含了对最初请求的名字的资源记录。回答报文中的回答区域可以包含多条RR，因此**一个主机名能够有多个IP地址，例如负载均衡**。每个RR包含：Name, Type, Class, TTL (Time To Live，缓存时间), RDLENGTH (数据长度), RDATA (实际数据，如IP地址)。
- **权威区域 (Authority)** 包含了其他权威服务器的记录。例如，如果本地域名服务器不是权威服务器，它可能会在这里返回权威服务器的NS记录。
- **附加区域 (Additional)** 包含了其他有帮助的记录。例如对于一个MX请求的回答报文的回答区域包含了一条资源记录，提供了邮件服务器的规范主机名。而附加区域中**包含了一个类型A记录**，提供**用于该邮件服务器的规范主机名的IP地址**。（这样客户端就不用再查一次邮件服务器的IP了，很贴心）

可以对照这张图片再看一下对应的字段：

![dns](https://picture.cry4o4n0tfound.cn/crywebsite/2025/05/dns.png)

最后，dns 是网络攻击中的重点受害者，可以看到我们 wireshark 中抓的包，dns 发出去的包（查询）一般只会携带一个询问 xxx.xxx.com 是在哪里？但是返回（响应）却带来了一系列 ns 服务器的 ip 地址以及对应想要查询的网站的 ip 地址，这对于消耗服务器资源是很有帮助的。这引出了**DNS放大攻击**：攻击者向公共DNS服务器发送大量伪造源IP（受害者的IP）的DNS查询请求，DNS服务器会将数倍于请求大小的响应发送给受害者，造成DDoS。

DNS通常使用**UDP**作为传输层协议，端口号**53**。因为查询通常很小且要求快速响应，UDP开销小。但如果响应数据过大（超过512字节）或需要进行区域传送（AXFR/IXFR），则会使用**TCP**。

可以查看 Cloudflare 官方对于 dns 的[一些解析](https://www.google.com/url?sa=E&q=https%3A%2F%2Fwww.cloudflare.com%2Fzh-cn%2Flearning%2Fdns%2Fcommon-dns-issues%2F)。

于是我们完成了第一步。查询到了 cry4o4n0tfound.cn 对应的 ip 地址（实际上都是 cloudflare 的 cdn 服务器），接下来我们需要看返回的内容了。

------

## HTTP(**Hypertext Transfer Protocol**):

HTTP，超文本传输协议，是我们上网冲浪的基石。浏览器和Web服务器之间沟通就靠它了。它是**应用层**协议，通常运行在TCP之上。

http 在计网考试中似乎考的不多，但很多 api 设计，例如 REST API 这些，都是基于 htpp 头的一些设计来进行的，所以其实很重要。

但在谈 http 之前，其实我们更应该谈一谈 tls，毕竟，现在的网站基本都是 http + tls 的 https 了。

### TLS/SSL (Transport Layer Security / Secure Sockets Layer):

让我们看一看 tls 的包：

![tls](https://picture.cry4o4n0tfound.cn/crywebsite/2025/05/tls.png)

TLS 是为了 HTTP 加密而诞生的（其实不止HTTP，很多协议都可以跑在TLS上），旨在保护大家的隐私。不知道大家有没有这样的记忆，小时候宽带快欠费了，于是上网浏览网页的时候会跳出运营商提醒续费的服务，这就是因为裸的 HTTP 没有加密，所以运营商可以人为的在 http 数据段添加一些它们的内容，从而大家早年间的上网就是裸奔。HTTPS = HTTP + TLS。

加密的前提显然是需要交换密钥，通过密钥对于内容加密，而交换则需要建立连接，TLS 这里的 Client Hello 与 Server Hello 就是类似于 TCP 三次握手建立连接的过程，但它更复杂，涉及到：

1. **Client Hello**: 客户端向服务器发送它支持的TLS版本、一堆加密套件（Cipher Suites，即加密算法组合）、一个随机数（Client Random）。如果访问特定域名，还会带上SNI。
2. **Server Hello**: 服务器从客户端提供的加密套件中选择一个双方都支持的，确定TLS版本，返回自己的随机数（Server Random），并发送自己的**数字证书**（包含了公钥和权威CA的签名）。
3. **(可选) Certificate Request/Server Key Exchange/Server Hello Done**: 服务器可能要求客户端也提供证书（双向认证），或者发送一些额外的密钥交换信息（如Diffie-Hellman参数）。
4. **Client Key Exchange/Change Cipher Spec/Encrypted Handshake Message**: 客户端验证服务器证书。然后生成一个预主密钥（Pre-Master Secret），用服务器的公钥加密后发送给服务器。接着客户端发送一个Change Cipher Spec消息，通知服务器后续通信将使用协商好的密钥和算法进行加密。最后发送一个加密的Finished消息。
5. **Server Change Cipher Spec/Encrypted Handshake Message**: 服务器用自己的私钥解密得到预主密钥。客户端和服务器都使用 Client Random, Server Random, Pre-Master Secret推导出会话密钥（对称密钥）。服务器也发送Change Cipher Spec和加密的Finished消息。

握手完成后，双方就用这个会话密钥（对称加密）来加密后续的HTTP通信了。对称加密比非对称加密快得多，所以非对称加密只用于握手阶段安全地交换对称密钥。

这里的 **SNI (Server Name Indication)** 是 server name indication，因为一个服务器可能托管多个服务（多个域名），但多个服务对应的网站可能不同，从而证书不一样（每个域名通常有自己的证书）。于是我们需要在 TLS 握手前（Client Hello中）提供我实际要访问的网站域名，从而服务器能确定返回哪一张证书进行加密。实际上，很多协议就是在 tls 上做文章，比如 reality，就是通过多加一层 sni ，把实际的 sni 封装到数据段，然后使代理服务器解包后来访问对应的服务，当然，在计网复习这里这并不重要...

详细的 tls 介绍可以参考，tls1.2、tls1.3 主要是优化了加密算法以及降低握手的 RTT（比如TLS1.3将握手从2-RTT减少到1-RTT，甚至0-RTT用于会话恢复）：

[https://blog.csdn.net/llzhang_fly/article/details/126594555](https://www.google.com/url?sa=E&q=https%3A%2F%2Fblog.csdn.net%2Fllzhang_fly%2Farticle%2Fdetails%2F126594555)

对应的 tls 中的证书申请，以及其中的认证方式是一件很复杂的事，考试本身也不怎么考 tls，有兴趣可以了解[有关 tls/ssl 证书的一切](https://www.google.com/url?sa=E&q=https%3A%2F%2Fwww.kawabangga.com%2Fposts%2F5330)

### HTTP 方法：

HTTP定义了一组请求方法，以指示在给定资源上要执行的期望操作。

| 方法 (Method) | 描述                                         | 是否允许报文主体 (Body Allowed) | 幂等性 (Idempotent) | 安全性 (Safe) |
| ------------- | -------------------------------------------- | ------------------------------- | ------------------- | ------------- |
| GET           | 请求获取指定的资源                           | 否                              | 是                  | 是            |
| POST          | 向服务器提交数据以创建或更新资源             | 是                              | 否                  | 否            |
| HEAD          | 请求与GET方法相同的响应，但响应体不返回      | 否                              | 是                  | 是            |
| PUT           | 用请求中的有效载荷替换目标资源的所有当前表示 | 是                              | 是                  | 否            |
| DELETE        | 删除指定的资源                               | 否                              | 是                  | 否            |
| OPTIONS       | 请求关于服务器支持的通信选项的信息           | 否                              | 是                  | 是            |
| PATCH         | 对资源应用部分修改                           | 是                              | 否                  | 否            |
| CONNECT       | 建立一个到由目标资源标识的服务器的隧道       | 是 (for handshake)              | 否                  | 否            |
| TRACE         | 对目标资源执行一个消息环回测试               | 否                              | 是                  | 是            |

- **幂等性 (Idempotent)**：多次执行相同的操作，结果都是相同的（例如，多次调用DELETE删除同一个资源，第一次删除成功，后续调用虽然可能返回不同状态码如404，但资源状态保持为“已删除”）。
- **安全性 (Safe)**：HTTP方法如果是安全的，那它不应该改变服务器上的资源状态（例如GET, HEAD, OPTIONS）。

常用的其实只有 GET 和 POST，其余的 PUT，DELETE 在 RESTful API 设计中也很重要，但面试基础可能问得少。

- **GET**：通常用于请求数据，参数附加在 URL 后面 (?key1=value1&key2=value2)，长度有限制，会被浏览器缓存，不应用于敏感数据。
- **POST**：通常用于提交数据（如表单），数据放在请求体 (Request Body) 中，对数据大小无严格限制，不会被缓存，相对GET更安全一点（但只是说参数不在URL里，数据本身在HTTPS下才安全）。

### HTTP 报文结构：

HTTP 报文分为请求报文 (Request Message) 和响应报文 (Response Message)。

**请求报文 (Request Message):**

![http](https://picture.cry4o4n0tfound.cn/crywebsite/2025/05/http.png)

1. **请求行 (Request Line)**: GET /index.html HTTP/1.1
   - 方法 (Method): GET, POST 等
   - 请求URI (Request-URI): /path/to/resource?query_string
   - HTTP版本 (HTTP-Version): HTTP/1.1, HTTP/2
2. **请求头部 (Request Headers)**: 一系列键值对，提供关于请求或客户端的附加信息。
   - Host: `www.example.com `(HTTP/1.1必需)
   - User-Agent: Mozilla/5.0 ... (浏览器标识)
   - Accept: text/html,application/xhtml+xml,... (客户端能接受的内容类型)
   - Accept-Language: en-US,en;q=0.5 (接受的语言)
   - Cookie: name=value (携带之前服务器设置的cookie)
   - Content-Type: application/json (POST请求时，说明请求体格式)
   - Content-Length: 123 (POST请求时，请求体长度)
3. **空行 (Empty Line)**: CR+LF，用于分隔头部和主体。
4. **请求主体 (Request Body)**: 可选，POST, PUT, PATCH 方法通常携带数据。

**响应报文 (Response Message):**

1. **状态行 (Status Line)**: HTTP/1.1 200 OK
   - HTTP版本 (HTTP-Version): HTTP/1.1
   - 状态码 (Status Code): 如 200, 404, 500
   - 原因短语 (Reason Phrase): 如 OK, Not Found, Internal Server Error
2. **响应头部 (Response Headers)**: 一系列键值对，提供关于响应或服务器的附加信息。
   - Date: Mon, 20 May 2024 10:00:00 GMT (响应生成时间)
   - Server: Apache/2.4.1 (Unix) (服务器软件信息)
   - Content-Type: text/html; charset=UTF-8 (响应体内容类型和字符集)
   - Content-Length: 4567 (响应体长度)
   - Set-Cookie: session_id=abcdef; HttpOnly (让客户端保存cookie)
   - Cache-Control: max-age=3600 (缓存控制)
3. **空行 (Empty Line)**: CR+LF。
4. **响应主体 (Response Body)**: 实际的资源内容，如 HTML 页面、JSON 数据、图片等。

**常见的 HTTP 状态码:**

- 1xx (Informational): 请求已接收，继续处理。
- 2xx (Successful): 操作成功接收、理解和接受。
  - 200 OK: 请求成功。
  - 201 Created: 请求成功并且服务器创建了新的资源。
  - 204 No Content: 服务器成功处理了请求，但没有返回任何内容。
- 3xx (Redirection): 需要进一步的操作以完成请求。
  - 301 Moved Permanently: 请求的资源已永久移动到新URI。
  - 302 Found (HTTP/1.0) / 303 See Other / 307 Temporary Redirect (HTTP/1.1): 临时重定向。
  - 304 Not Modified: 资源未修改，客户端可以使用缓存版本 (用于条件GET)。
- 4xx (Client Error): 请求包含语法错误或无法完成请求。
  - 400 Bad Request: 服务器不理解请求的语法。
  - 401 Unauthorized: 请求要求用户的身份认证。
  - 403 Forbidden: 服务器理解请求客户端的请求，但是拒绝执行此请求。
  - 404 Not Found: 服务器未找到请求的资源。
- 5xx (Server Error): 服务器在处理请求的过程中发生了错误。
  - 500 Internal Server Error: 服务器遇到了一个未曾预料的状况，导致了它无法完成对请求的处理。
  - 503 Service Unavailable: 服务器当前无法处理请求（例如，过载或维护）。

不过报文阶段也不怎么考，所以不过多赘述，反正要搞开发也肯定绕不开 HTTP 请求头的学习，到时候补上就是了。

（以下转载自 [kiprey](https://www.google.com/url?sa=E&q=https%3A%2F%2Fkiprey.github.io%2F2021%2F05%2Fcnatda-1%2F)) 学长的博客

**关于web 缓存**

- Web缓存也称代理服务器，其工作流程如下：
  - 浏览器创建一个到Web缓存器的TCP连接，并向Web缓存器中的对象发送一个 HTTP 请求。
  - Web缓存器进行检查
    - 如果本地存储了对象副本，则Web缓存器向客户浏览器用HTTP响应报文返回该对象。
    - 如果没有存储该对象，则打开一个与该对象的初始服务器的TCP连接，并在该连接上发起一个HTTP请求。受到请求后，初始服务器向该web缓存器发送具有该对象的http响应。
      当Web缓存器接收到对象后，在本地存储空间存储一份副本，并向客户的浏览器用HTTP响应报文发送该副本。
- 存放在Web缓存器中的对象副本可能是陈旧的，而http协议允许缓存器证实它的对象是最新的，即**条件GET**方法：
  - 请求报文使用 GET 方法
  - 请求报文中包含一个 If-Modified-Since:  首部行或者 If-None-Match: 
    如果Web缓存器向初始服务器发送**条件get**报文时：
  - 目标对象没有发生改变，则初始服务器返回一个 304 Not Modified 响应，报文中的body为空。Web缓存器直接用本地副本响应客户端。
  - 目标对象已经改变，初始服务器返回一个 200 OK 响应，报文中存放新的对象。Web缓存器更新本地副本并响应客户端。

上述的 web 缓存其实到今天已经演化成了 cdn。

### CDN（**Content Delivery Network**）：

很显然，我们不能每次都从服务器拉取网页。要知道，在中国，服务器的带宽非常的贵...

所以厂商们选择将内容分发到 cdn 提供商的服务器上，比如 bilibili 在长沙的 cdn 服务器就托管在超算，减少了内容分发的固定成本。这样，当用户请求时，实际请求的就是最近的 CDN 服务器中已经存储的内容（可能是地理位置最近，也可能是网络延迟最低），而如果请求的内容 CDN 服务器中没有（称为 Cache Miss），CDN 服务器才会从原服务器（Origin Server）中请求拉取，然后缓存。大多数 CDN 使用 DNS 来截获和重定向请求（DNS 的奇妙用法，例如将` www.example.com` 解析到离用户最近的 CDN 边缘节点的 IP），详细内容位于[这里](https://www.google.com/url?sa=E&q=https%3A%2F%2Fzhuanlan.zhihu.com%2Fp%2F164474457)

CDN 主要缓存静态资源（如图片、CSS、JS文件、视频），对于动态内容，CDN 可能只做路径优化或部分缓存。

CDN 的不同的服务器安置原则（截取自书中，反正期中考了...）：

- **深入 (Enter Deep)**：该原则是通过在遍及全球的接入 ISP 中部署服务器集群来深入到 ISP 的接入网中。由 Akamai 首创。其目标是靠近端用户，通过减少端用户和 CDN 集群之间（内容从这里收到）链路和路由器的数量，从而改善了用户感受的时延和吞吐量。因为这种高度分布式设计，维护和管理集群的任务成为挑战。
- **邀请做客 (Bring Home)**：该原则是通过在少量（例如 10 个）关键位置建造大集群来 *邀请到 ISP 做客*。该原则由 Limelight 和许多其他 CDN 公司所采用。不是将集群放在接入 ISP 中，这些 CDN 通常将它们的集群放置在因特网交换点（IXP）。与深入设计原则相比，邀请做客设计通常产生较低的维护和管理开销，可能以对端用户的较高时延和较低吞吐量为代价。

**HTTP/1.0, HTTP/1.1, HTTP/2, HTTP/3 的演进**

- **HTTP/1.0**: 短连接，每次请求响应都建立新的TCP连接，效率低。
- **HTTP/1.1**:
  - **长连接 (Persistent Connections)**: 默认开启 (Connection: keep-alive)，一个TCP连接可处理多个HTTP请求。
  - **管道化 (Pipelining)**: 客户端可以连续发送多个请求，而不用等待前一个响应返回。但服务器必须按序响应，如果第一个响应慢，会阻塞后续（队头阻塞 Head-of-Line Blocking）。实际效果不佳，很多浏览器默认关闭。
  - **Host 头部**: 支持虚拟主机，一个IP可以托管多个域名。
- **HTTP/2**:
  - **二进制分帧 (Binary Framing)**: 将HTTP消息分解为更小的帧，二进制编码，解析更高效。
  - **多路复用 (Multiplexing)**: 在一个TCP连接上并行处理多个请求和响应，请求和响应可以乱序发送和接收，通过流ID匹配，解决了HTTP/1.1的队头阻塞问题。
  - **头部压缩 (Header Compression - HPACK)**: 压缩HTTP头部，减少开销。
  - **服务器推送 (Server Push)**: 服务器可以主动向客户端推送资源，而无需客户端明确请求。
- **HTTP/3**:
  - 基于 **QUIC (Quick UDP Internet Connections)** 协议，QUIC 运行在 UDP 之上。
  - 解决了TCP队头阻塞问题：TCP层面如果一个包丢了，会阻塞整个TCP连接上的所有HTTP/2流。QUIC的流是独立的，一个流的丢包不影响其他流。
  - 更快的连接建立：QUIC集成了TLS握手，可以实现0-RTT或1-RTT连接建立。
  - 连接迁移：当客户端网络变化时（如Wi-Fi切换到4G），QUIC连接可以保持，无需重新建立。

------

# 传输层：

应用层的数据（比如一个HTTP请求报文）准备好后，就需要交给运输层打包发往目的地了。运输层主要负责端到端（进程到进程）的通信。

## UDP(**User Datagram Protocol**):

也可以称作 Unreliable Datagram Protocol（不可靠数据报协议），但“User”才是官方的。

UDP 是一种**无连接**的、**不可靠**的传输协议。它只在 IP 数据报服务之上增加了两个最基本的服务：**复用 (Multiplexing)** 和 **分用 (Demultiplexing)**，以及少量的差错检测。

- **无连接 (Connectionless)**: 发送数据前不需要建立连接。想发就发，直接把数据包（称为UDP数据报）扔给网络层。
- **不可靠 (Unreliable)**: 不保证数据报一定到达，不保证按序到达，不进行流量控制和拥塞控制。如果数据报丢失、重复或失序，UDP本身不做任何处理，需要应用层自己来处理。
- **尽力而为 (Best-effort delivery)**: 和IP层一样。
- **消息导向 (Message-oriented)**: 应用层交下来的报文，UDP添加首部后直接向下交付给IP层，既不合并也不拆分。接收方的UDP剥掉首部后，原封不动地将报文交给上层应用进程。
- **开销小，延迟低**: 首部开销小（仅8字节），无需连接建立和维护，处理速度快。

**UDP 报文段结构 (UDP Segment Structure):**

  

- **源端口 (Source Port)** (16位): 发送方进程的端口号。可选，如果不需要回复，可以全0。
- **目的端口 (Destination Port)** (16位): 接收方进程的端口号。必需。
- **长度 (Length)** (16位): UDP报文段的总长度（首部+数据），单位是字节。最小值为8（只有首部）。
- **校验和 (Checksum)** (16位): 用于检测UDP报文段在传输中是否发生差错（首部或数据部分）。可选，如果发送方没有计算校验和，则此字段全0。计算时会包含一个“伪首部”（包含源IP、目的IP、协议号等信息），以防止IP地址被篡改后UDP包被错误交付。

**UDP 的应用场景:**

- DNS (Domain Name System): 查询请求小，要求快速响应。
- DHCP (Dynamic Host Configuration Protocol): 获取IP地址等配置。
- TFTP (Trivial File Transfer Protocol): 简单文件传输。
- SNMP (Simple Network Management Protocol): 网络管理。
- RTP (Real-time Transport Protocol): 常用于流媒体（如VoIP、视频会议），通常由应用层自己处理可靠性。
- 在线游戏：对实时性要求高，少量丢包可以容忍。
- QUIC (HTTP/3的基础): 故意选择UDP，以避免TCP的队头阻塞等问题，并在应用层实现可靠性、拥塞控制等。

关于队头阻塞：

## TCP (**Transmission Control Protocol**):

TCP，传输控制协议，是互联网核心协议簇（TCP/IP）中最重要的协议之一。与UDP不同，TCP提供的是**面向连接的、可靠的**字节流服务。

详细的 tcp 讲解：https://juanha.github.io/2018/05/05/tcp/

以下只是转译：

- **面向连接 (Connection-oriented)**: 通信双方在传输数据之前必须先建立连接（三次握手），数据传输结束后要释放连接（四次挥手）。
- **可靠传输 (Reliable)**:
  - **序列号 (Sequence Numbers) 和 确认号 (Acknowledgement Numbers)**: TCP将数据分割成它认为最适合发送的数据块（报文段）。它给每个字节都编上一个序号，接收方通过确认号告知发送方已正确接收到哪些字节。
  - **超时重传 (Retransmission Timeout)**: 发送方发送数据后会启动一个计时器，如果在规定时间内没有收到确认，就认为数据丢失，会重新发送。
  - **校验和 (Checksum)**: 类似UDP，检验数据在传输过程中是否出错。
  - **有序交付 (Ordered Delivery)**: 接收方会根据序列号对收到的数据进行排序，确保应用层按序接收。
- **全双工通信 (Full-duplex)**: 连接双方可以同时发送和接收数据。
- **流量控制 (Flow Control)**: 使用**滑动窗口 (Sliding Window)**机制，接收方告诉发送方自己还有多少缓冲区空间（窗口大小），防止发送方过快发送数据导致接收方处理不过来。
- **拥塞控制 (Congestion Control)**: 当网络发生拥塞时，TCP会减少发送数据的速率，以缓解网络压力。主要算法有：慢启动 (Slow Start)、拥塞避免 (Congestion Avoidance)、快重传 (Fast Retransmit)、快恢复 (Fast Recovery)。

### **TCP 报文段结构 (TCP Segment Structure):**

![tcp](https://picture.cry4o4n0tfound.cn/crywebsite/2025/05/tcp.png)

- **源端口 (Source Port)** (16位) 和 **目的端口 (Destination Port)** (16位): 标识发送和接收进程。
- **序列号 (Sequence Number)** (32位): 本报文段所发送数据的第一个字节的序号。在建立连接时，双方会商定一个初始序列号 (ISN)。
- **确认号 (Acknowledgment Number)** (32位): 期望收到的下一个字节的序号。只有当ACK标志位为1时才有效。表示此序号之前的所有字节都已正确接收。
- **数据偏移 (Data Offset / Header Length)** (4位): TCP首部的长度，以4字节为单位。最小为5（20字节，无选项）。
- **保留 (Reserved)** (6位): 未使用，必须为0。
- **标志位 (Flags)** (6位):
  - **URG (Urgent)**: 紧急指针有效。
  - **ACK (Acknowledgment)**: 确认号有效。
  - **PSH (Push)**: 接收方应尽快将这个报文段交给应用层，不再等待填满缓冲区。
  - **RST (Reset)**: 重置连接。用于异常关闭连接。
  - **SYN (Synchronize)**: 发起一个连接。
  - **FIN (Finish)**: 释放一个连接。
- **窗口大小 (Window Size)** (16位): 用于流量控制。指示发送本报文段的一方（接收方）当前可用的缓冲区大小（字节数）。
- **校验和 (Checksum)** (16位): 检验首部和数据。计算时也包含TCP伪首部。
- **紧急指针 (Urgent Pointer)** (16位): 只有当URG标志为1时才有效。指出本报文段中紧急数据的字节数。
- **选项 (Options)** (可变长度): 如最大报文段长度 (MSS)、窗口扩大因子、时间戳等。
- **填充 (Padding)**: 确保首部长度是4字节的整数倍。

### **TCP 连接管理:**

1. **三次握手 (Three-Way Handshake) - 建立连接:**

   - **客户端 -> 服务器**: SYN=1, seq=x (客户端请求建立连接，x是客户端的初始序列号)
     - 客户端："你好，我想和你建立连接，我的初始序列号是x，可以吗？" (SYN)
   - **服务器 -> 客户端**: SYN=1, ACK=1, seq=y, ack=x+1 (服务器同意连接，y是服务器的初始序列号，确认收到客户端的SYN)
     - 服务器："你好，我同意连接，我的初始序列号是y，我收到了你的序列号x，期待你的x+1。" (SYN-ACK)
   - **客户端 -> 服务器**: ACK=1, seq=x+1, ack=y+1 (客户端确认收到服务器的SYN，连接建立)
     - 客户端："好的，我收到了你的序列号y，期待你的y+1。现在连接建立了！" (ACK)
       为什么是三次？主要是为了防止已失效的连接请求报文段突然又传送到了服务器，从而产生错误。两次握手无法确认客户端的接收能力和服务器的发送能力都正常。

2. **四次挥手 (Four-Way Handshake) - 断开连接:**
   由于TCP是全双工的，所以每一方都必须单独地进行关闭。

   - **主动方 (如客户端) -> 被动方 (如服务器)**: FIN=1, seq=u (客户端请求关闭连接)

     - 客户端："我这边没有数据要发给你了，准备关闭了。" (FIN)

   - **被动方 -> 主动方**: ACK=1, seq=v, ack=u+1 (服务器确认收到客户端的关闭请求)

     - 服务器："收到你的关闭请求了。但我可能还有数据要发，你等我一下。" (ACK)
       此时，客户端到服务器方向的连接关闭 (半关闭状态)，服务器仍可以向客户端发送数据。

   - **被动方 -> 主动方**: FIN=1, ACK=1, seq=w, ack=u+1 (服务器也准备好关闭连接了)

     - 服务器："我这边数据也发完了，我也准备关闭了。" (FIN)

   - **主动方 -> 被动方**: ACK=1, seq=u+1, ack=w+1 (客户端确认收到服务器的关闭请求)

     - 客户端："好的，收到你的关闭请求了。" (ACK)
       此时，客户端会进入 TIME_WAIT 状态，等待2MSL (Maximum Segment Lifetime，报文最大生存时间) 后才真正关闭，确保网络中残余的报文段都已消失。服务器收到ACK后立即关闭。

       

### **TCP 拥塞控制 (Congestion Control):**

TCP  不仅仅要考虑发送方和接收方之间的流量匹配（流量控制），更要考虑整个网络的拥塞状况。如果网络中的数据量超过了路由器的处理能力，就会导致数据包丢失、延迟增大，这就是网络拥塞。TCP 的拥塞控制机制旨在防止发送方过快地向网络注入数据，从而避免或减轻网络拥塞。

TCP 拥塞控制是一个动态的过程，主要通过维护一个**拥塞窗口 (Congestion Window, cwnd)** 来实现。发送方实际可发送的数据量取**拥塞窗口 (cwnd)** 和**接收方通告的窗口 (rwnd, 即接收窗口)** 中的较小者，即：
EffectiveWindow = min(cwnd, rwnd)

拥塞控制主要包含以下几个核心算法和阶段：

1. **慢启动 (Slow Start)**:
   - **目的**: 在连接刚建立或因超时检测到拥塞后，逐渐增大 cwnd，以探测网络的可用带宽，避免一开始就发送大量数据导致网络瘫痪。
   - **机制**:
     - 连接建立时，cwnd 通常初始化为一个较小的值，比如 1 MSS (Maximum Segment Size，最大报文段长度)。
     - 每收到一个对新数据的 ACK，cwnd 就增加 1 MSS。
     - 这意味着，在一个 RTT (Round-Trip Time) 内，如果所有发出的报文段都得到确认，cwnd 就会翻倍（指数增长）。例如，cwnd 从 1 -> 2 -> 4 -> 8 MSS...
   - **结束条件**:
     - 当 cwnd 达到一个预设的**慢启动阈值 (Slow Start Threshold, ssthresh)** 时，慢启动结束，进入拥塞避免阶段。
     - 如果发生超时丢包，ssthresh 会被设置为当前 cwnd 的一半（但不小于2 MSS），并且 cwnd 重新设置为 1 MSS，重新开始慢启动。
2. **拥塞避免 (Congestion Avoidance)**:
   - **目的**: 在 cwnd 达到 ssthresh 后，采用更保守的方式增加 cwnd，缓慢探测更多可用带宽，避免过快增长再次导致拥塞。
   - **机制**:
     - 当 cwnd >= ssthresh 时，进入拥塞避免阶段。
     - 每经过一个 RTT（即所有 cwnd 内的数据都被确认），cwnd 增加 1 MSS（线性增长）。更精确地说，每收到一个 ACK，cwnd 增加 MSS * (MSS / cwnd)。这样在一个 RTT 内，cwnd 大约增加 1 MSS。
   - **结束条件**:
     - 如果发生超时丢包，处理方式同慢启动中的超时：ssthresh 设为当前 cwnd 的一半，cwnd 设为 1 MSS，回到慢启动。
     - 如果通过“快重传”检测到丢包（收到3个冗余ACK），则进入快恢复阶段。
3. **快重传 (Fast Retransmit)**:
   - **目的**: 当发送方连续收到多个（通常是3个）对同一个报文段的冗余ACK (Duplicate ACK) 时，TCP 就认为这个 ACK 指示的序号之后的那个报文段很可能已经丢失了。此时，发送方不必等待超时计时器到期，而是立即重传这个被认为丢失的报文段。
   - **为什么是3个冗余ACK?**:
     - 少数冗余ACK可能是由于网络中的报文段失序到达引起的。
     - 连续3个冗余ACK表明，有3个后续的报文段已经到达接收方，但它们之前的某个报文段丢失了。这强烈暗示了丢包，而不是简单的失序。
   - **机制**: 发送方一旦收到第3个冗余ACK，立即重传它认为丢失的报文段，而不等待该报文段的重传计时器超时。
4. **快恢复 (Fast Recovery)**:
   - **目的**: 在快重传之后，网络可能只是发生了轻微拥塞，而不是像超时那样严重的拥塞。因此，不需要像超时那样将 cwnd 剧烈减小到 1 MSS。
   - **机制 (以 Reno 算法为例)**:
     - 当发送方执行快重传时（收到3个冗余ACK）：
       - 将 ssthresh 设置为当前 cwnd 的一半（ssthresh = cwnd / 2）。
       - 将 cwnd 设置为新的 ssthresh 再加上3个MSS（cwnd = ssthresh + 3 * MSS）。这3个MSS是为了补偿那3个已经离开网络的冗余ACK对应的报文段。
       - （更经典或早期的做法是 cwnd = cwnd / 2 或 cwnd = ssthresh，然后进入拥塞避免。但加上3 MSS是Reno的一个特点，用于在等待重传确认期间“膨胀”窗口）。
     - 此后，每再收到一个冗余ACK，cwnd 增加 1 MSS（继续膨胀窗口，因为每个冗余ACK表示又有一个包离开了网络并到达了接收端）。
     - 当收到对丢失报文段的新的ACK时（即重传成功）：
       - 将 cwnd 设置为 ssthresh（即降下来的拥塞窗口值）。
       - 从快恢复状态转入拥塞避免状态。

**拥塞控制状态图的简化理解：**

- **初始状态**: cwnd = 1 MSS, ssthresh 通常为一个较大的值。
- **慢启动阶段**: cwnd 指数增长。
  - 若 cwnd < ssthresh，保持慢启动。
  - 若 cwnd >= ssthresh，进入拥塞避免。
  - 若 **发生超时**：ssthresh = cwnd / 2, cwnd = 1 MSS，重新进入慢启动。
- **拥塞避免阶段**: cwnd 线性增长。
  - 若 **发生超时**：ssthresh = cwnd / 2, cwnd = 1 MSS，重新进入慢启动。
  - 若 **收到3个冗余ACK** (触发快重传)：
    - ssthresh = cwnd / 2
    - cwnd = ssthresh + 3 * MSS (或直接 cwnd = ssthresh)
    - 进入快恢复阶段。
- **快恢复阶段**:
  - 重传丢失的报文段。
  - 每收到一个冗余ACK，cwnd += MSS。
  - 若收到对重传报文段的**新ACK**：cwnd = ssthresh，进入拥塞避免阶段。
  - 若在此阶段**再次发生超时**：ssthresh = cwnd / 2 (当前的，可能膨胀的cwnd), cwnd = 1 MSS，重新进入慢启动。

**TCP 拥塞控制的演进：**
上述描述主要基于 TCP Reno 版本。后续还有许多改进的拥塞控制算法，如：

- **TCP Tahoe**: 更早期的版本，无论是超时还是收到3个冗余ACK，都会将 cwnd 降为1 MSS，进入慢启动。没有快恢复阶段。
- **TCP NewReno**: 对 Reno 的快恢复阶段进行了改进，能更好地处理多个包在同一个窗口内丢失的情况。
- **TCP SACK (Selective Acknowledgment)**: 允许接收方告知发送方哪些报文段已经收到，哪些丢失，使发送方能更精确地重传，避免不必要的重传。
- **TCP Vegas**: 基于 RTT 变化来判断拥塞，试图在拥塞发生前就调整发送速率。
- **CUBIC**: Linux 系统中默认的拥塞控制算法，设计用于高带宽、高延迟网络（长肥网络 LFN）。它使用一个三次函数来调整窗口增长。
- **BBR (Bottleneck Bandwidth and Round-trip propagation time)**: Google 开发的较新的拥塞控制算法，它不依赖丢包作为拥塞信号，而是主动探测网络的瓶颈带宽和RTT。

**总结来说，TCP拥塞控制是一个复杂的反馈系统，它通过：**

1. **慢启动**来快速填充网络管道。
2. **拥塞避免**来小心地维持高吞吐量。
3. **快重传**来对可能的丢包做出快速反应。
4. **快恢复**来在轻微拥塞后更快地恢复传输速率。
5. 并在发生严重拥塞（超时）时，通过大幅降低发送速率来缓解。

**TCP 的应用场景:**

- HTTP/HTTPS (Web浏览)
- FTP/SFTP (文件传输)
- SMTP, POP3, IMAP (电子邮件)
- SSH (安全远程登录)
- 任何要求高可靠性的数据传输。

tcp 这里需要了解的部分很多，特别是三次握手、四次挥手、流量控制和拥塞控制的细节，这些都是“面试常考点”。

------

# 网络层：

运输层将数据（TCP报文段或UDP数据报）打包好后，就交给了网络层。网络层的主要任务是实现**主机到主机**的通信，也就是负责将数据包从源主机路由到目的主机，这可能需要跨越多个网络。

网络层的协议需要知道的大概就只有 ICMP 和 IP，ICMP 也只是作为 IP “尽力而为”的 debug 协议。

让我们从 ip 包头开始：

![ip](https://picture.cry4o4n0tfound.cn/crywebsite/2025/05/ip.png)



这是IPv4的报头：

- **版本 (Version)** (4位): 指IP协议的版本，对于IPv4，就是4。
- **首部长度 (Header Length / IHL)** (4位): IP包头的长度，以4字节为单位。最小值为5（即20字节，没有选项字段）。最大为15（60字节）。
- **服务类型 (Type of Service / TOS)** (8位): 非常幽默的一个东西，可以理解为该数据包的重要程度，反正就是可以告诉路由器该数据包的优先级以及需要的服务质量（如低延迟、高吞吐量、高可靠性）。但早期路由器大多忽略此字段，现在有了区分服务（DiffServ）和集成服务（IntServ），这个字段又被重新利用（称为DS字段和ECN字段）。
- **总长度 (Total Length)** (16位): 整个IP数据报的长度（首部+数据），以字节为单位。最大长度为65535字节。
- **标识 (Identification / Packet ID)** (16位): 用于标识不同的数据包，当IP数据报长度超过MTU (Maximum Transmission Unit，最大传输单元) 而需要分片时，所有属于同个原始数据报的分片都具有相同的标识值。这样目的主机才能将它们重新组装。
- **标志 (Flags)** (3位): 也是与数据包是否分片有关。
  - 第1位：保留，必须为0。
  - 第2位：**DF (Don't Fragment)**。DF=1表示禁止分片；DF=0表示允许分片。如果一个包设置了DF=1，但路由器必须分片才能转发它，路由器会丢弃该包并发送一个ICMP“需要分片但DF置位”的错误消息。
  - 第3位：**MF (More Fragments)**。MF=1表示后面还有分片；MF=0表示这是最后一个分片（或未分片）。
- **片偏移 (Fragment Offset)** (13位): 较长的分组在分片后，某片在原分组中的相对位置。以8字节为单位。
- **生存时间 (Time To Live / TTL)** (8位): 比较重要的一个点，也就是数据包最多可以经过多少跳（路由器），每经过一个路由器，TTL减1。当TTL减为0时，路由器会丢弃该包，并发送一个ICMP“TTL超时”错误消息给源主机。这有效避免了数据包在网络中无限循环，也是 traceroute 的检验原理。
- **协议 (Protocol ID)** (8位): 指出此数据报携带的数据（上层协议）是什么类型。常见值：1 (ICMP), 6 (TCP), 17 (UDP)。
- **首部校验和 (Header Checksum)** (16位): 用于校验IP首部在传输过程中是否出错。只校验首部，不校验数据部分。因为每经过一个路由器，TTL会变，所以校验和需要重新计算。
- **源地址 (Source Address)** (32位): 发送方的IPv4地址。
- **目的地址 (Destination Address)** (32位): 接收方的IPv4地址。
- **选项 (Options)** (可变长度，如果首部长度>20字节): 可用于安全、路由记录、时间戳等，但很少使用，因为会增加路由器处理开销。
- **数据 (Data)**: 携带的来自传输层的数据，比如TCP报文段或UDP用户数据报。

## ICMP(**Internet Control Message Protocol**):

ICMP，互联网控制报文协议。它不传输用户数据，而是用于在IP主机、路由器之间传递**控制消息**，报告错误或提供有关网络状况的信息。ICMP 报文是封装在 IP 数据报中的（IP数据报的数据部分就是ICMP报文）。

![icmp](https://picture.cry4o4n0tfound.cn/crywebsite/2025/05/icmp.png)

ICMP 最常见的用途是 ping。ping 程序发送 ICMP **回显请求 (Echo Request)** 报文，目标主机收到后会回复 ICMP **回显应答 (Echo Reply)** 报文， icmp 报文会承载在 ip 的数据段中进行发送。

**常见的 ICMP 报文类型:**

- **类型0: 回显应答 (Echo Reply)** - 对ping的响应。
- **类型3: 目标不可达 (Destination Unreachable)** - 当路由器或主机无法将数据报交付给目标时发送。具体原因通过“代码”字段指出，如：
  - 代码0: 网络不可达
  - 代码1: 主机不可达
  - 代码2: 协议不可达
  - 代码3: 端口不可达
  - 代码4: 需要分片但DF位置位
- **类型5: 重定向 (Redirect)** - 路由器告知主机，有另一条更好的路径到达特定目标。
- **类型8: 回显请求 (Echo Request)** - ping命令发送。
- **类型11: 超时 (Time Exceeded)** -
  - 代码0: TTL超时。traceroute 命令利用这个原理，发送TTL逐渐增大的IP包，每个路由器TTL减到0时会返回此ICMP消息，从而追踪路径。
  - 代码1: 分片重组超时。
- **类型12: 参数问题 (Parameter Problem)** - IP首部字段不正确。

ICMP对于网络诊断非常重要。

## IP(Internet Protocol)：

IP 协议是TCP/IP协议簇的核心，提供**无连接的、不可靠的、尽力而为的**数据报服务。

- **无连接**: 发送数据前不建立连接。每个数据报独立路由，可能走不同路径。
- **不可靠**: 不保证数据报能成功到达目的地，也不保证按序到达，不保证数据完整性（虽然有首部校验和，但只校验首部）。可靠性由上层协议（如TCP）保证。
- **尽力而为**: IP协议会尽最大努力把数据报送到目的地，但不做任何保证。

**IP 地址和子网掩码:**
IPv4地址是32位二进制数，通常用点分十进制表示（如 192.168.1.1）。
子网掩码用于区分一个IP地址中的网络部分和主机部分。例如 255.255.255.0 表示前24位是网络号，后8位是主机号。
IP地址与子网掩码进行**按位与**运算，可以得到网络地址。

**路由 (Routing):**
路由器根据其**路由表 (Routing Table)** 来决定如何转发IP数据报。路由表中的条目通常包含：目的网络地址、下一跳地址（或出接口）。路由器查找路由表时，会使用**最长前缀匹配**原则。

**IP 分片与重组 (Fragmentation and Reassembly):**
当IP数据报的大小超过链路的MTU时，发送方主机或中间路由器需要将其分片。每个分片都是一个独立的IP数据报，有自己的IP首部（大部分与原数据报相同，但总长度、标志、片偏移会修改）。
分片的重组只在**目的主机**进行。因为中间路由器不知道最终路径上的最小MTU，且重组耗费资源。

**IPv6:**
由于IPv4地址耗尽，IPv6被设计出来。IPv6地址是128位，地址空间极大。IPv6报头格式也做了简化和优化，取消了首部校验和（由链路层和传输层保证），分片只能由源主机进行等。

经过 ip 的包装后，我们的数据包已经快裹成粽子了。

![数据包裹粽子](https://picture.cry4o4n0tfound.cn/crywebsite/2025/05/structure.png)

------

# 链路层：

此时原始的 http 请求已经包装了一层 TCP (或UDP) 和 IP 了（即 [IP Header [TCP Header [HTTP Data]]] 或 [IP Header [UDP Header [DNS Data]]] ），即将通过局域网发向世界。网络层负责主机到主机的逻辑通信，而链路层则负责**节点到节点（相邻节点，如主机到路由器，或路由器到路由器）的物理通信**。它将网络层的IP数据报封装成**帧 (Frame)** 进行传输。

但包装在 ip 包后，我们还需要考虑一个问题，ip 本身是怎么来的（对于主机而言），我们肯定不能凭空给自己发一个 ip，不然小时候和朋友联机 mc 也不用跑去服务器，而数据包又是如何找到路由器（或局域网内的其他主机）发出去的，于是这里就涉及到了 DHCP 和 ARP。

## 本地局域网内：

### DHCP(**Dynamic Host Configuration Protocol**):

DHCP 是一种网络协议，**处于应用层与传输层之间，或者说，它使用 UDP 来实现其功能，但本身不属于应用层**，主要用于自动地为网络中的设备（例如计算机、手机、打印机等）分配 IP 地址、子网掩码、默认网关、DNS 服务器地址等网络配置信息。它的主要目的是简化网络管理，减少手动配置 IP 地址的工作量，并避免 IP 地址冲突。DHCP工作在**应用层**，但它通常在主机接入网络，需要IP地址时最先运行，使用UDP作为传输协议（客户端端口68，服务器端口67）。

想象一下，你在一个公共场所，打开一个公共 wifi 试图连接，或者你的电脑插上网线，它需要一个IP地址才能上网。手动配太麻烦了，DHCP就是来干这个的。它会弹出一个 web 页面（captive portal）让你登录，而这个时候就需要给你分配一个 ip 地址，有了 ip 地址你才能局域网内找到网关，从而通过网关走向世界。

**DHCP 工作流程 (DORA):**

让我们抓一个寝室的数据包来看一看：

![dhcp](https://picture.cry4o4n0tfound.cn/crywebsite/2025/05/dhcp.png)

1. **Discover (发现)**: 客户端以广播方式发送 DHCP DISCOVER 报文，寻找DHCP服务器。（“有没有DHCP服务器啊？我需要个IP地址！”）
2. **Offer (提供)**: 网络中（可能不止一个）DHCP服务器收到Discover报文后，从地址池中选择一个可用的IP地址，并连同其他配置信息，通过广播（或单播，如果知道客户端MAC）方式发送 DHCP OFFER 报文给客户端。（“我这里有个IP 192.168.1.100，你要不要？”）
3. **Request (请求)**: 客户端收到一个或多个Offer报文后，选择其中一个（通常是第一个到达的），然后以广播方式发送 DHCP REQUEST 报文，请求使用该IP地址。（“好，我就要服务器A提供的那个IP 192.168.1.100！”）
4. **Acknowledge (确认)**: 被选中的DHCP服务器发送 DHCP ACKNOWLEDGE 报文，确认将该IP地址分配给客户端，并包含租期等信息。其他未被选中的服务器则收回它们提供的IP。客户端收到ACK后，配置网络参数，就可以上网了。（“没问题，IP 192.168.1.100 归你了，租期是24小时。”）

### ARP(Adress Resolution Protocol):

ARP，地址解析协议。我们知道在IP网络中，通信靠IP地址。但在局域网（如以太网）中，设备间实际通信靠的是**MAC地址 (Media Access Control Address)**，也叫物理地址，是网卡出厂时固化的唯一标识。
ARP的作用就是：在知道了目标设备的IP地址后，如何找出它对应的MAC地址。ARP工作在网络层和链路层之间，但通常归类为链路层协议（或网络层协议的辅助）。

**ARP 工作流程:**
假设主机A (IP_A, MAC_A) 要给同一局域网内的主机B (IP_B) 发送数据，但A只知道IP_B，不知道MAC_B。

再看一下 arp 的包，在位于链路层和网络层之间传递信息，尤其在寝室这种环境下，由于 arp 的广播特性，抓到的包一半都是 arp：

![arp](https://picture.cry4o4n0tfound.cn/crywebsite/2025/05/arp.png)

1. 主机A先查看自己的**ARP缓存表 (ARP Cache)**，看是否有IP_B对应的MAC_B记录。
2. 如果缓存中没有：
   - 主机A在局域网内广播一个 **ARP请求 (ARP Request)** 报文：“谁的IP地址是 IP_B？请告诉我你的MAC地址。我的IP是 IP_A，MAC是 MAC_A。” 这个请求的目标MAC地址是广播MAC地址 (FF:FF:FF:FF:FF:FF)。
3. 局域网内所有主机都会收到这个ARP请求：
   - 其他主机发现请求的IP不是自己的，就忽略它。
   - 主机B发现请求的IP是自己的 (IP_B)，于是它会：
     - 将主机A的IP和MAC地址 (IP_A, MAC_A) 存入自己的ARP缓存表（因为A以后可能也要给B回包）。
     - 向主机A**单播**一个 **ARP响应 (ARP Reply)** 报文：“我是 IP_B，我的MAC地址是 MAC_B。”
4. 主机A收到ARP响应后，将 (IP_B, MAC_B) 存入自己的ARP缓存表，然后就可以用MAC_B作为目标MAC地址，封装IP数据报成帧，发送给主机B了。

如果目标IP地址不在同一子网，主机会将数据包发给**默认网关 (路由器)**，此时ARP解析的是网关的MAC地址。

**RARP (Reverse ARP)**: 反向地址解析协议，知道MAC地址，查询IP地址。已被DHCP取代。（可以参考 cs144 中 lab5 的内容）

除此之外， arp 洪水攻击就源自于 arp 的广播特性，攻击者可以伪造一个假装询问的客户端，然后发一大堆实际上根本不存在的 mac 地址，然后来消耗主机的资源缓存。

好了，走的这一步， cry4o4n0tfound.cn 要开始走向路由器了。

### 以太网 (Ethernet):

以太网是当今最普遍的局域网技术。它定义了链路层的帧格式和介质访问控制方法。
**以太网帧结构 (Ethernet II Frame):**

​    

- **前同步码 (Preamble)** 和 **帧首定界符 (SFD - Start Frame Delimiter)**: 用于同步和标识帧的开始。
- **目的MAC地址 (Destination MAC Address)** 和 **源MAC地址 (Source MAC Address)**: 6字节（48位）的物理地址。
- **类型/长度 (EtherType/Length)**: 如果值大于等于1536 (0x0600)，则表示类型（如0x0800代表IPv4，0x0806代表ARP，0x86DD代表IPv6）。如果小于等于1500，则表示数据部分的长度（IEEE 802.3格式）。
- **数据 (Payload)**: 通常是IP数据报。最小46字节（不足会填充），最大1500字节（这是以太网的MTU）。
- **帧检验序列 (FCS - Frame Check Sequence)**: 4字节CRC校验码，用于检测帧在传输中是否出错。

**MAC地址**: 全球唯一，48位，通常表示为6组十六进制数（如 00:1A:2B:3C:4D:5E）。

**CSMA/CD (Carrier Sense Multiple Access with Collision Detection)**:
载波侦听多路访问/冲突检测。是以太网（特别是早期的共享总线型）使用的介质访问控制方法。

- **载波侦听 (Carrier Sense)**: 发送前先听网络是否空闲。
- **多路访问 (Multiple Access)**: 多个设备共享同一传输介质。
- **冲突检测 (Collision Detection)**: 边发送边检测是否发生冲突（两个设备同时发送）。如果检测到冲突，立即停止发送，发送一个拥塞信号，然后各自随机等待一段时间后再尝试重发（二进制指数退避算法）。
  现在普遍使用交换式以太网，每个端口独占带宽，冲突域大大减小，全双工模式下CSMA/CD通常不启用。

### WIFI (IEEE 802.11):

无线局域网标准。与有线以太网类似，但介质是无线电波。
**CSMA/CA (Carrier Sense Multiple Access with Collision Avoidance)**:
载波侦听多路访问/冲突避免。由于无线环境复杂，无法像有线那样有效检测冲突（“隐藏终端”和“暴露终端”问题），所以采用**避免冲突**的策略。

- 发送前侦听信道。
- 如果信道空闲，等待一段随机时间 (DIFS + Backoff) 后再发送。
- 使用 **确认 (ACK)** 机制：接收方正确收到数据帧后，会回复一个ACK帧。如果发送方没收到ACK，会认为数据丢失并重传。
- 可选的 **RTS/CTS (Request to Send/Clear to Send)** 机制：对于大数据帧，发送方先发一个RTS，接收方回复CTS，通知其他站点在一段时间内不要发送，以减少冲突概率。

**WIFI 相关概念:**

- **SSID (Service Set Identifier)**: 无线网络的名称。
- **BSS (Basic Service Set)**: 一个AP (Access Point) 和与之关联的无线客户端组成一个BSS。
- **ESS (Extended Service Set)**: 多个BSS通过有线网络连接起来，形成一个更大的逻辑网络，共享同一个SSID。
- **无线安全**:
  - WEP (Wired Equivalent Privacy): 已被破解，不安全。
  - WPA (Wi-Fi Protected Access)
  - WPA2 (使用AES加密，目前主流)
  - WPA3 (更新的安全特性)

## 局域网外：

>  以下这些协议都是路由层次的协议，所谓的三层设备协议，按道理应该归到网络层，但是为了方便模拟寻找路由的过程，就放在链路层了

此时数据包已经成功离开你的设备，通过ARP找到了网关（路由器）的MAC地址，封装成以太网帧发给了网关。网关会解开帧，看到IP包头的目标IP地址，然后查询自己的路由表，决定下一跳发给哪个路由器。这个过程会一直持续，直到数据包到达目标IP所在的网络。这就涉及到路由选择协议了。

而涉及到选择，基本就离不开算法，所以路由协议基本就是图论之间的较量。

路由协议分为：

- **内部网关协议 (IGP - Interior Gateway Protocol)**: 在一个自治系统 (AS - Autonomous System) 内部使用的路由协议。一个AS通常是一个ISP或一个大型组织的网络。
  - RIP
  - OSPF
- **外部网关协议 (EGP - Exterior Gateway Protocol)**: 在不同自治系统之间交换路由信息的协议。
  - BGP

### RIP(**Routing Information Protocol**):

- **类型**: 距离矢量协议 (Distance-Vector)。
- **度量 (Metric)**: 跳数 (Hop Count)。每经过一个路由器算一跳。最大15跳，16跳表示不可达。适用于小型网络。
- **工作原理**:
  - 每个路由器维护一张路由表，包含到每个目标网络的距离（跳数）和下一跳路由器。
  - 定期（如每30秒）与相邻路由器交换整个路由表。
  - 根据收到的信息更新自己的路由表（Bellman-Ford算法）。
- **缺点**:
  - 收敛慢（好消息传得快，坏消息传得慢，容易产生路由环路，虽有水平分割、毒性反转等机制缓解）。
  - 最大跳数限制了网络规模。
  - 只考虑跳数，不考虑带宽、延迟等。
- **版本**: RIPv1 (有类路由), RIPv2 (无类路由，支持VLSM和CIDR), RIPng (用于IPv6)。

### OSPF(**Open Shortest Path First**):

- **类型**: 链路状态协议 (Link-State)。
- **度量 (Metric)**: 代价 (Cost)，通常与链路带宽成反比。管理员可配置。
- **工作原理**:
  1. **发现邻居**: 路由器使用Hello包发现直连的邻居，并建立邻接关系。
  2. **分发链路状态**: 每个路由器将其直连接口的链路状态信息（如链路ID、状态、代价）封装成 **链路状态通告 (LSA - Link-State Advertisement)**，并洪泛 (Flooding) 给AS内的所有其他路由器。
  3. **构建链路状态数据库 (LSDB)**: 每个路由器收集所有LSA，构建出整个AS的拓扑图。
  4. **运行SPF算法**: 每个路由器以自己为根节点，使用Dijkstra算法（最短路径优先算法）计算到其他所有节点的最短路径树。
  5. **填充路由表**: 根据最短路径树生成路由表。
- **优点**:
  - 收敛快。
  - 无路由环路（因为每个路由器都有全局拓扑信息）。
  - 支持VLSM和CIDR。
  - 支持区域 (Area)划分，减少LSA洪泛范围，实现层次化路由，适用于大型网络。
- **缺点**: 计算复杂，对路由器CPU和内存要求较高。

### RIP 与 OSPF 的比较：

RIP 使用 UDP:  RIP 使用 UDP 的原因是 UDP 简单、开销小，适合广播路由信息。 RIP 需要定期向邻居广播路由表，UDP 的广播特性可以方便地实现这一点。

OSPF 直接使用 IP: OSPF 不使用 TCP 或 UDP 的原因是为了提高效率和可靠性，**所以 OSPF 直接承载在 IP 层内，在 IP 的 protocol id 中有自己的协议号**。

效率: TCP 协议有三次握手等机制，会增加开销。 OSPF 需要快速地传播链路状态更新，直接使用 IP 可以减少开销。
可靠性: OSPF 自己实现了可靠性机制，例如链路状态确认和重传。 如果使用 TCP，则 OSPF 的可靠性机制和 TCP 的可靠性机制会产生冲突。

那为什么还需要 RIP 呢？问就是配置简单，适合小型网络（<s>历史遗留原因</s>



### BGP(**Border Gateway Protocol**):

- **类型**: 路径矢量协议 (Path-Vector)。是目前互联网上唯一使用的EGP。

- **目的**: 在自治系统 (AS) 之间交换网络可达性信息，并实施路由策略。BGP不关心AS内部的拓扑细节。

- **工作原理**:
  - BGP路由器（称为BGP发言人）之间建立TCP连接（端口179）来交换路由信息。
  - 路由信息包含目标网络前缀和一系列AS路径属性 (Path Attributes)，最重要的属性是 **AS-PATH**（数据包到达目标网络所要经过的AS序列）。
  - BGP使用AS-PATH来避免路由环路（如果收到的路由更新中AS-PATH包含了自身的AS号，则丢弃该更新）。
  - BGP的路由选择是基于策略的，而不仅仅是最短路径。管理员可以配置策略来影响路径选择（如优先选择某个ISP，避免经过某个AS等）。
  
- **特点**:
  - 非常复杂，但高度可控。
  - 增量更新，只发送变化了的路由信息。
  - 可靠性高（使用TCP）。
  - 设计用于大规模网络（整个互联网）。
  
  bgp 其实就是各大 as 自治系统的互相商量妥协，如果你是小运营商，那么通过 bgp 协议走我的地方就需要交“保护费"，毕竟我的线路这么完善，可以让你联通更多的地方还不需要部署线路的费用。

------

# 一些补充的协议：

## SMTP(**Simple Mail Transfer Protocol**):

SMTP，简单邮件传输协议，是互联网上传输电子邮件的标准**应用层**协议。它通常使用TCP端口25。

- **用途**: 主要用于**发送邮件**，即从邮件客户端 (MUA - Mail User Agent, 如Outlook, Foxmail) 发送到邮件服务器 (MSA - Mail Submission Agent)，以及邮件服务器 (MTA - Mail Transfer Agent, 如Sendmail, Postfix) 之间中继邮件。

- **工作模式**: 客户端/服务器模式。SMTP客户端发起连接，发送命令和邮件数据；SMTP服务器响应命令并接收邮件。

- **主要命令**:
  - HELO / EHLO <domain>: 客户端向服务器标识自己。
  - MAIL FROM:<`sender@example.com`>: 指定发件人。
  - RCPT TO:<`recipient@example.com>`: 指定收件人（可多次使用指定多个收件人）。
  - DATA: 通知服务器开始传输邮件内容。
  - . (单独一行): 邮件内容结束。
  - QUIT: 关闭连接。
  
  **可以参考 cs144 lab0 中的邮件发送内容**
  
- **邮件格式**: 通常遵循MIME (Multipurpose Internet Mail Extensions) 标准，允许邮件包含文本、HTML、图片、附件等。

- **限制**: SMTP本身不进行身份验证（早期设计），容易被滥用发送垃圾邮件。现在通常配合ESMTP (Extended SMTP) 使用身份验证 (SMTP AUTH) 和加密 (STARTTLS)。

- **与POP3/IMAP的关系**: SMTP负责“推”邮件（发送），而POP3 (Post Office Protocol v3, TCP端口110) 和IMAP (Internet Message Access Protocol, TCP端口143) 负责“拉”邮件，即MUA从邮件服务器上下载和管理邮件。

## P2P( **Peer-to-Peer**):

P2P，对等网络。与传统的客户端/服务器 (C/S) 模型不同，P2P网络中的每个节点（称为对等方，Peer）既可以是客户端，也可以是服务器。它们直接相互连接并交换信息/资源，无需中心服务器。

- **特点**:
  - **去中心化/分布式**: 没有单一故障点，鲁棒性高。
  - **可扩展性好**: 新节点加入可以同时带来服务能力和请求负载。
  - **资源共享**: 文件、计算能力、带宽等。
  - **自组织**: 节点可以自由加入和离开。
- **挑战**:
  - 资源发现困难（如何找到想要的资源和提供该资源的节点）。
  - 安全性、匿名性问题。
  - NAT/防火墙穿透。
  - “搭便车”问题（只下载不上传）。
- **常见应用**:
  - **文件共享**: BitTorrent, eMule。
    - **BitTorrent**:
      - **Tracker**: 一个服务器，协调Peers，但不传输文件数据。Peers向Tracker注册自己拥有的文件块，并获取其他拥有所需文件块的Peers列表。
      - **Peers**: 下载和上传文件块的节点。
      - **Seeds**: 拥有完整文件的Peer。
      - **Leeches**: 正在下载但未完成的Peer。
      - **Swarm**: 针对一个特定Torrent文件，所有参与下载和上传的Peers的集合。
      - .torrent 文件: 包含文件的元数据（如文件名、大小、分块信息）和Tracker服务器地址。
  - **即时通讯**: Skype (早期版本)。
  - **加密货币**: Bitcoin, Ethereum (节点之间同步账本)。
  - **流媒体**: PPLive (早期)。

steam 的家庭共享和所谓的 udp 打洞，以及 tailscale 等vpn 服务，其实都有利用 p2p 的思想。

我觉得 p2p 的核心主旨思想就是：**两个点都得知道对方的位置，如果两个点，其中有一个的 ip 地址是经过一层 nat 转换的，尤其是严格的对称 nat ，那么我们就需要一个中转服务器，也就是所谓的(STUN/TURN server)，也就是有一个确定的位置，让我们能做交换信息的地方。**有了交换信息的中心，两个点之间就能间接的架起连接沟通的桥梁，当然，如果能直接连接就更好了。

------

## 整体流程回顾：从URL到页面展示

1. **输入URL**: https://cry4o4n0tfound.cn
2. **DNS解析 (应用层)**:
   - 浏览器/系统缓存检查 cry4o4n0tfound.cn 的IP。
   - 没有则向本地域名服务器发起DNS查询（通常用UDP）。
   - 本地域名服务器通过迭代/递归查询，最终从权威DNS服务器获得 cry4o4n0tfound.cn 对应的IP地址（比如Cloudflare CDN节点的IP 104.21.50.123）。
3. **建立TCP连接 (运输层)**:
   - 浏览器知道目标IP (104.21.50.123) 和HTTPS默认端口(443)。
   - 发起TCP三次握手，与服务器建立TCP连接。
     - 客户端 (SYN) -> 服务器 (SYN-ACK) -> 客户端 (ACK)
4. **TLS握手 (会话层/应用层安全)**:
   - 在TCP连接之上进行TLS握手，协商加密算法，交换密钥，验证服务器证书。SNI字段会指明要访问 cry4o4n0tfound.cn。
5. **HTTP请求 (应用层)**:
   - 浏览器构建HTTP请求报文 (GET /index.html HTTP/1.1 或 HTTP/2)，通过加密的TLS通道发送给服务器。
   - Host: cry4o4n0tfound.cn
   - 其他头部如 User-Agent, Accept 等。
6. **服务器处理请求**:
   - Web服务器 (如Nginx, Apache) 接收到请求，解析。
   - 如果是CDN节点，检查是否有缓存，没有则回源站取。
   - 服务器找到 index.html 文件（或动态生成页面）。
7. **HTTP响应 (应用层)**:
   - 服务器构建HTTP响应报文 (如 HTTP/1.1 200 OK)，包含HTML内容，通过TLS加密后发送给浏览器。
   - Content-Type: text/html
   - 其他头部如 Content-Length, Set-Cookie 等。
8. **浏览器渲染页面**:
   - 浏览器接收响应，解密，解析HTML。
   - 发现HTML中引用了其他资源（CSS, JS, 图片），会为每个资源重复上述类似过程（可能复用已建立的TCP/TLS连接，或新建连接）去请求它们。
   - 执行JS，应用CSS，最终将页面展示给用户。
9. **关闭/保持连接 (运输层)**:
   - 根据HTTP版本和头部设置，可能保持连接 (Keep-Alive) 以便后续请求，或在数据传输完毕后四次挥手关闭TCP连接。

**数据包的封装与解封装之旅 (以HTTP请求为例):**

- **发送方 (客户端)**:
  1. **应用层**: HTTP请求数据。
  2. **运输层**: 添加TCP头部 (源/目的端口, 序列号等) -> TCP报文段。
  3. **网络层**: 添加IP头部 (源/目的IP, TTL等) -> IP数据报。
  4. **链路层**: 添加以太网头部 (源/目的MAC, 类型) 和尾部 (FCS) -> 以太网帧。
  5. **物理层**: 转换为比特流，通过网线/无线电波发送。
- **路由器 (中间节点)**:
  1. **物理层**: 接收比特流，转换回帧。
  2. **链路层**: 检查FCS，剥掉以太网头部和尾部，得到IP数据报。
  3. **网络层**: 检查目的IP，查询路由表，确定下一跳，修改TTL，重新计算IP首部校验和。
  4. **链路层**: 封装新的以太网头部 (源MAC是本路由器出接口MAC，目的MAC是下一跳MAC)，添加FCS。
  5. **物理层**: 转换为比特流发出。
- **接收方 (服务器)**:
  1. **物理层**: 接收比特流，转换回帧。
  2. **链路层**: 检查FCS，剥掉以太网头部和尾部，得到IP数据报。
  3. **网络层**: 检查协议字段，剥掉IP头部，得到TCP报文段。
  4. **运输层**: 检查端口号，剥掉TCP头部，得到HTTP请求数据。
  5. **应用层**: Web服务器处理HTTP请求。

这个过程就是数据从上层向下层层封装，然后在网络中传输，到达目的地后再从下层向上层层解封装的过程。

至此，我们终于结束了这次访问。

---

# 肖老师的必考点整理：

（大概是唯一准备带上考场的内容了😂）

## load balancing：

不知道怎么考，想不出来考法以及考点。所以让 gemini 做的总结

负载均衡 (Load Balancing) 是一种将网络流量或计算负载有效地分配到多个服务器或其他计算资源上的技术。其主要目的是优化资源利用率、最大化吞吐量、最小化响应时间，并避免任何单一资源的过载，从而提高系统的可用性和可靠性。

**考点/核心概念：**

1. **目的与优势：**
   - **提高性能/吞吐量：** 通过并行处理请求。
   - **提高可用性/可靠性：** 如果一台服务器故障，负载均衡器可以将流量重定向到其他健康的服务器。
   - **可伸缩性：** 方便地增加或减少后端服务器数量以应对需求变化。
   - **简化管理：** 对外提供单一访问点。
2. **常见的负载均衡算法/策略：**
   - **轮询 (Round Robin):** 按顺序将每个新请求分配给下一个服务器。
   - **加权轮询 (Weighted Round Robin):** 给性能更强的服务器分配更高的权重，使其接收更多请求。
   - **最少连接 (Least Connections):** 将新请求分配给当前活动连接数最少的服务器。
   - **加权最少连接 (Weighted Least Connections):** 结合服务器性能权重和最少连接。
   - **源地址哈希 (Source IP Hash):** 根据请求的源IP地址进行哈希计算，将同一客户端的请求始终定向到同一台服务器。这有助于保持会话。
   - **URL哈希 (URL Hash):** 根据请求的URL进行哈希，可用于缓存优化。
   - **最快响应时间 (Least Response Time):** 将请求分配给响应最快的服务器（通常结合健康检查）。
3. **负载均衡的实现层次：**
   - **DNS 负载均衡 (应用层):** 通过DNS解析将一个域名解析到多个不同的IP地址，实现简单的流量分配。缺点是TTL缓存可能导致流量切换不及时，且无法感知后端服务器的实际负载或健康状况。
   - **L4 负载均衡 (传输层):** 工作在OSI模型的传输层，基于IP地址和端口号进行流量分发（如TCP、UDP）。不关心应用层内容，速度快。常见的有LVS (Linux Virtual Server)。
   - **L7 负载均衡 (应用层):** 工作在OSI模型的应用层，可以理解HTTP、HTTPS、FTP等协议内容。能够根据URL、HTTP头部、Cookie等信息进行更智能的路由决策，可以实现SSL卸载、内容缓存、HTTP压缩等功能。常见的有Nginx、HAProxy。
4. **关键技术/特性：**
   - **健康检查 (Health Checks):** 负载均衡器定期检查后端服务器的健康状况（如通过ping、尝试连接特定端口或请求特定URL），以确保只将流量发送到健康的服务器。
   - **会话保持/会话粘性 (Session Persistence / Sticky Sessions):** 对于某些应用（如购物车、登录状态），需要将来自同一客户端的多个请求定向到同一台后端服务器。实现方式有：
     - 基于源IP地址
     - 基于Cookie
     - 基于Session ID (通过URL重写或HTTP头部)
   - **SSL 卸载 (SSL Offloading):** 由负载均衡器处理SSL/TLS的加密解密工作，减轻后端服务器的CPU负担。
   - **高可用性 (High Availability, HA) of Load Balancer Itself:** 负载均衡器本身不能成为单点故障，通常会采用主备或集群方式部署。

**可能的考法：**

- 解释不同负载均衡算法的原理和适用场景。
- 比较L4和L7负载均衡的区别。
- 解释会话保持的必要性和实现方法。
- DNS负载均衡的优缺点。

## atm 协议：

（不了解，直接带上考场就完了）

ATM (Asynchronous Transfer Mode)，异步传输模式，是一种面向连接的分组交换技术，它在20世纪90年代被广泛认为是下一代网络的核心技术。 虽然现在已经被其他技术（如以太网）所取代，但了解 ATM 协议对于理解网络技术的发展仍然很有价值。

**ATM 的核心概念：**

- **面向连接：** 在数据传输之前，必须先建立一条虚拟电路 (Virtual Circuit, VC)。
- **固定长度信元 (Fixed-Size Cells)：** ATM 将所有数据分割成固定长度的信元，每个信元包含 53 字节，其中 5 字节是头部，48 字节是有效载荷。
- **异步时分复用 (Asynchronous Time Division Multiplexing)：** 多个虚拟电路共享同一物理链路，每个虚拟电路根据需要分配时隙。

**ATM 的特点：**

- **高速：** ATM 设计用于高速数据传输，最初的目标是支持 155 Mbps 和 622 Mbps 的速率。
- **QoS (Quality of Service) 支持：** ATM 提供了多种 QoS 机制，可以保证不同类型业务的带宽、延迟和抖动等性能指标。
- **可扩展性：** ATM 可以支持多种类型的业务，包括语音、视频和数据。
- **面向连接：** 简化了网络管理和控制，但也增加了建立连接的开销。
- **固定长度信元：** 简化了交换机的设计，提高了交换速度，但也可能导致带宽浪费。

**ATM 的协议栈：**

ATM 的协议栈可以分为以下几层：

- **物理层 (Physical Layer)：** 负责将 ATM 信元转换为物理信号，并在物理介质上传输。 ATM 可以使用多种物理层协议，例如 SONET/SDH、T1/E1 和光纤。

- ATM 层 (ATM Layer)：

  负责信元的交换和复用。 ATM 层的主要功能包括：

  - **信元头部处理：** 包括 VPI/VCI 查找、信元复用和解复用。
  - **信元交换：** 根据信元头部中的 VPI/VCI 将信元转发到正确的输出端口。
  - **流量控制：** 防止网络拥塞。

- ATM 适配层 (ATM Adaptation Layer, AAL)：

   负责将不同类型的业务数据转换为 ATM 信元，并将 ATM 信元转换为业务数据。 ATM 提供了多种 AAL 协议，例如：

  - **AAL1：** 用于支持恒定比特率 (Constant Bit Rate, CBR) 业务，例如语音和视频。
  - **AAL2：** 用于支持可变比特率 (Variable Bit Rate, VBR) 业务，例如视频会议。
  - **AAL3/4：** 用于支持面向连接的数据传输。
  - **AAL5：** 用于支持面向连接和无连接的数据传输，例如 LAN 仿真 (LAN Emulation, LANE) 和 IP over ATM。

**ATM 的信元结构：**

ATM 信元由 5 字节的头部和 48 字节的有效载荷组成。

- 头部 (Header)：
  - **GFC (Generic Flow Control)：** 用于流量控制。
  - **VPI (Virtual Path Identifier)：** 虚拟路径标识符，用于标识虚拟路径。
  - **VCI (Virtual Channel Identifier)：** 虚拟信道标识符，用于标识虚拟信道。
  - **PT (Payload Type)：** 有效载荷类型，用于指示信元中包含的数据类型。
  - **CLP (Cell Loss Priority)：** 信元丢失优先级，用于指示信元的重要性。
  - **HEC (Header Error Control)：** 头部错误控制，用于检测和纠正头部错误。
- **有效载荷 (Payload)：** 包含实际的数据。

**ATM 的应用：**

ATM 曾经被广泛应用于：

- **骨干网络：** 用于构建高速骨干网络。
- **局域网：** 用于构建高速局域网，例如 LANE。
- **宽带接入：** 用于提供宽带接入服务，例如 ADSL over ATM。

**ATM 的衰落：**

尽管 ATM 具有许多优点，但由于以下原因，它最终被其他技术所取代：

- **复杂性：** ATM 的协议栈比较复杂，配置和管理比较困难。
- **成本：** ATM 设备的成本比较高。
- **以太网的崛起：** 以太网技术不断发展，速率不断提高，成本不断降低，逐渐取代了 ATM。
- **IP 的普及：** IP 协议成为互联网的核心协议，IP over Ethernet 成为主流的组网方式。

## RDMA (RemoteDirect Memory Access):

[RDMA](https://zhida.zhihu.com/search?content_id=240841230&content_type=Article&match_order=1&q=RDMA&zhida_source=entity)([RemoteDirect Memory Access](https://zhida.zhihu.com/search?content_id=240841230&content_type=Article&match_order=1&q=RemoteDirect+Memory+Access&zhida_source=entity))技术全称远程直接内存访问，就是为了解决网络传输中客户端与服务器端数据处理的延迟而产生的。它将数据直接从一台计算机的内存传输到另一台计算机，无需双方操作系统的介入。这允许高吞吐、低延迟的网络通信，尤其适合在大规模并行计算机集群中使用。RDMA通过网络把资料直接传入计算机的内存中，将数据从一个系统快速移动到远程系统内存中，而不对操作系统造成任何影响，这样就不需要用到多少计算机的处理能力。它消除了数据包在用户空间和内核空间复制移动和上下文切换的开销，因而能解放内存带宽和CPU周期用于改进应用系统性能。

目前，大致有三类RDMA网络，分别是Infiniband、RoCE、[iWARP](https://zhida.zhihu.com/search?content_id=240841230&content_type=Article&match_order=1&q=iWARP&zhida_source=entity)

。其中，Infiniband是一种专为RDMA设计的网络，从硬件级别保证可靠传输 ， 而RoCE 和  iWARP都是基于以太网的RDMA技术，支持相应的verbs接口，如图1所示。从图中不难发现，RoCE协议存在RoCEv1和RoCEv2两个版本，主要区别RoCEv1是基于以太网链路层实现的RDMA协议(交换机需要支持PFC等流控技术，在物理层保证可靠传输)，而RoCEv2是以太网TCP/IP协议中UDP层实现。从性能上，很明显Infiniband网络最好，但网卡和交换机是价格也很高，然而RoCEv2和iWARP仅需使用特殊的网卡就可以了，价格也相对便宜很多。

1. Infiniband，支持RDMA的新一代网络协议。 由于这是一种新的网络技术，因此需要支持该技术的NIC和交换机。
2. RoCE，一个允许在以太网上执行RDMA的网络协议。 其较低的网络标头是以太网标头，其较高的网络标头（包括数据）是InfiniBand标头。 这支持在标准以太网基础设施（交换机）上使用RDMA。 只有网卡应该是特殊的，支持RoCE。
3. iWARP，一个允许在TCP上执行RDMA的网络协议。 IB和RoCE中存在的功能在iWARP中不受支持。 这支持在标准以太网基础设施（交换机）上使用RDMA。  只有网卡应该是特殊的，并且支持iWARP（如果使用CPU卸载），否则所有iWARP堆栈都可以在SW中实现，并且丧失了大部分RDMA性能优势。

## dhcp 四个步骤：

人类的本质是复读机。

**DHCP 工作流程 (DORA):**

让我们抓一个寝室的数据包来看一看：

![dhcp](https://picture.cry4o4n0tfound.cn/crywebsite/2025/05/dhcp.png)

1. **Discover (发现)**: 客户端以广播方式发送 DHCP DISCOVER 报文，寻找DHCP服务器。（“有没有DHCP服务器啊？我需要个IP地址！”）
2. **Offer (提供)**: 网络中（可能不止一个）DHCP服务器收到Discover报文后，从地址池中选择一个可用的IP地址，并连同其他配置信息，通过广播（或单播，如果知道客户端MAC）方式发送 DHCP OFFER 报文给客户端。（“我这里有个IP 192.168.1.100，你要不要？”）
3. **Request (请求)**: 客户端收到一个或多个Offer报文后，选择其中一个（通常是第一个到达的），然后以广播方式发送 DHCP REQUEST 报文，请求使用该IP地址。（“好，我就要服务器A提供的那个IP 192.168.1.100！”）
4. **Acknowledge (确认)**: 被选中的DHCP服务器发送 DHCP ACKNOWLEDGE 报文，确认将该IP地址分配给客户端，并包含租期等信息。其他未被选中的服务器则收回它们提供的IP。客户端收到ACK后，配置网络参数，就可以上网了。（“没问题，IP 192.168.1.100 归你了，租期是24小时。”）

## fragment offset:

**Fragment Offset（分片偏移）** 是 IP 协议头部中的一个字段，用于在 IP 分片和重组过程中指示分片在原始数据报中的位置。

**背景：**

当一个 IP 数据报的大小超过了网络路径上某个链路的最大传输单元 (Maximum Transmission Unit, MTU) 时，就需要将该数据报分成更小的片段 (fragments) 进行传输。 这个过程称为 IP 分片 (IP Fragmentation)。

**Fragment Offset 的作用：**

- **指示分片的位置：** Fragment Offset 字段告诉接收方，当前分片在原始数据报中的起始位置。
- **重组数据报：** 接收方根据 Fragment Offset 字段将各个分片按照正确的顺序重新组合成原始的数据报。

**Fragment Offset 的细节：**

- **单位：** Fragment Offset 的单位是 8 字节 (octets)。 这意味着 Fragment Offset 的值乘以 8 才能得到分片在原始数据报中的实际偏移量 (以字节为单位)。
- **长度：** Fragment Offset 字段的长度是 13 位。
- 计算：
  - 第一个分片的 Fragment Offset 为 0。
  - 后续分片的 Fragment Offset 等于前一个分片的数据长度除以 8。
- 例子：
  - 如果一个原始数据报的大小是 4000 字节，MTU 是 1500 字节，那么可以分成三个分片：
    - 分片 1：大小 1480 字节 (1500 - 20 字节 IP 头部)，Fragment Offset = 0
    - 分片 2：大小 1480 字节，Fragment Offset = 1480 / 8 = 185
    - 分片 3：大小 1040 字节，Fragment Offset = (1480 + 1480) / 8 = 370

**与 More Fragments (MF) 标志位的关系：**

Fragment Offset 字段通常与 IP 头部中的 More Fragments (MF) 标志位一起使用。

- **MF = 1：** 表示当前分片不是最后一个分片，后面还有更多的分片。
- **MF = 0：** 表示当前分片是最后一个分片。

**接收方如何重组数据报：**

1. 接收方收到第一个分片后，会根据 IP 头部中的标识 (Identification) 字段将属于同一个原始数据报的所有分片收集起来。
2. 接收方根据 Fragment Offset 字段和 MF 标志位，将各个分片按照正确的顺序排列。
3. 当接收方收到所有分片 (即 MF = 0 的分片) 后，就可以将这些分片重新组合成原始的数据报。

## 划分子网:

划分子网是将一个大的IP网络块分割成多个较小的、独立的子网络（Subnet）的过程。这是IP网络管理中的一项基本且重要的技术。

**目的：**

1. **提高IP地址利用率：** 更有效地分配IP地址，避免浪费。通过VLSM（可变长子网掩码）可以根据不同子网的需求分配不同大小的地址块。
2. **减小广播域：** 广播消息（如ARP请求）会被限制在子网内部，不会泛洪到整个大网络，从而减少网络拥塞，提高网络性能。
3. **增强网络安全：** 可以在不同子网之间设置访问控制策略（如通过路由器或防火墙），隔离不同部门或服务。
4. **便于网络管理和故障排除：** 网络结构更清晰，问题定位更容易。

**核心概念：**

1. **IP地址：** 由网络部分和主机部分组成。
2. **子网掩码 (Subnet Mask)：** 一个32位的数值，用于区分IP地址中的网络部分（包括子网部分）和主机部分。掩码中为1的位对应网络部分，为0的位对应主机部分。
3. **网络地址 (Network Address)：** 标识一个特定的子网。计算方法：IP地址与子网掩码进行**按位与 (AND)** 运算。该地址的主机部分全为0。
4. **广播地址 (Broadcast Address)：** 用于向子网内所有主机发送消息的特殊地址。该地址的主机部分全为1。
5. **可用主机地址数量：** 一个子网中可以分配给实际设备的IP地址数量。计算公式：2^h - 2，其中h是主机部分的位数，减2是因为网络地址和广播地址不可用。
6. **CIDR (Classless Inter-Domain Routing)：** 无类域间路由。使用“/”加上网络前缀长度来表示子网掩码，例如 192.168.1.0/24 表示子网掩码是 255.255.255.0。

**如何划分子网：**

1. **确定需求：** 需要多少个子网？每个子网需要多少个主机地址？
2. **借位：** 从原始网络的主机部分“借用”若干位作为子网位。
   - 每借用1位，子网数量翻倍 (2^s 个子网, s为子网位数)。
   - 每借用1位，每个子网的主机位数减少1位，可用主机数相应减少。
3. **计算新的子网掩码：** 将借用的子网位在掩码中置为1。
4. **列出所有子网：**
   - 确定每个子网的网络地址。
   - 确定每个子网的广播地址。
   - 确定每个子网的可用主机地址范围。

**示例：**
假设有一个网络 192.168.1.0/24。我们想将其划分为4个子网。

1. 需求：4个子网。需要借用 log2(4) = 2 位作为子网位。
2. 原主机位有8位。借用2位后，子网位为2位，剩余主机位为 8 - 2 = 6 位。
3. 新子网掩码：/24 基础上再加2位，变为 /26，即 255.255.255.192 (二进制 11111111.11111111.11111111.11000000)。
4. 每个子网的可用主机数：2^6 - 2 = 64 - 2 = 62 个。
5. 子网划分：
   - **子网1：**
     - 子网位：00
     - 网络地址：192.168.1.0/26 (192.168.1.00000000)
     - 可用IP：192.168.1.1 - 192.168.1.62
     - 广播地址：192.168.1.63 (192.168.1.00111111)
   - **子网2：**
     - 子网位：01
     - 网络地址：192.168.1.64/26 (192.168.1.01000000)
     - 可用IP：192.168.1.65 - 192.168.1.126
     - 广播地址：192.168.1.127 (192.168.1.01111111)
   - **子网3：**
     - 子网位：10
     - 网络地址：192.168.1.128/26 (192.168.1.10000000)
     - 可用IP：192.168.1.129 - 192.168.1.190
     - 广播地址：192.168.1.191 (192.168.1.10111111)
   - **子网4：**
     - 子网位：11
     - 网络地址：192.168.1.192/26 (192.168.1.11000000)
     - 可用IP：192.168.1.193 - 192.168.1.254
     - 广播地址：192.168.1.255 (192.168.1.11111111)

**可能的考法：**

- 给定IP地址和子网掩码，计算网络地址、广播地址、可用主机数。
- 给定一个网络地址和需求（如子网数量或每个子网的主机数），设计子网划分方案，给出新的子网掩码和各子网的地址信息。
- VLSM的应用。

## RIP 算法：

**核心思想：**

每个路由器维护一张路由表，表中包含到达每个已知目标网络的“距离”（RIP中为跳数）和“方向”（下一跳路由器）。路由器只与直接相邻的路由器交换路由信息。

**算法步骤（简化版）：**

1. **初始化：**
   - 每个路由器知道到其直连网络的距离（通常为1跳）。
   - 到其他所有网络的距离初始化为无穷大（在RIP中是16跳）。
   - 下一跳为直接连接的接口或对端。
2. **信息交换 (Sharing)：**
   - **定期广播：** 每个路由器周期性地（RIP默认30秒）将其整个路由表（距离矢量）广播给所有直接相邻的路由器。
   - **触发更新 (Triggered Updates)：** 当检测到网络拓扑变化（如链路故障或新链路激活）时，立即发送更新，而不等待周期计时器。这有助于加快好消息的传播。
3. **路由计算/更新 (Updating)：**
   - 当一个路由器（假设为R1）收到来自邻居（假设为R2）的路由更新时，R1会对R2通告的每个目标网络（假设为D）进行如下计算：
     - Cost_to_D_via_R2 = Cost_from_R1_to_R2 + Cost_from_R2_to_D
       - Cost_from_R1_to_R2 是R1到邻居R2的链路成本（RIP中通常为1跳）。
       - Cost_from_R2_to_D 是R2在其路由更新中通告的到目标D的成本。
     - R1将这个计算出的 Cost_to_D_via_R2 与其当前路由表中到D的成本进行比较。
     - **如果 Cost_to_D_via_R2 更优（更小）：**
       - R1更新其路由表，将到D的下一跳设为R2，距离设为 Cost_to_D_via_R2。
     - **如果下一跳就是R2，但R2通告了一个更差的（或不变的）距离：**
       - R1也需要更新其路由表以反映R2的新信息（即使距离变差）。这很重要，因为R2可能失去了到达D的更优路径。

**RIP算法的问题及解决方案：**

- **慢收敛 (Slow Convergence) / 计数到无穷 (Counting to Infinity)：**
  - **问题描述：** 当网络中某条链路断开或度量变差（坏消息）时，信息在网络中传播较慢。路由器可能从其他邻居那里收到关于已失效路径的过时信息，导致路由表中该路径的跳数逐渐增加，直到达到最大值（无穷大），这个过程可能很慢并产生路由环路。
  - **解决方案：**
    1. **定义最大度量 (Maximum Metric)：** RIP将16跳定义为不可达（无穷大）。如果一个路由的跳数达到16，则认为该路径无效。
    2. **水平分割 (Split Horizon)：** 路由器不应该将它从某个接口学到的路由信息再通过同一个接口广播回去。这可以防止两个节点之间简单的路由环路。
    3. **毒性反转 (Poison Reverse / Split Horizon with Poison Reverse)：** 一种更强的水平分割。当路由器从一个接口学到某条路由后，它会通过该接口将这条路由广播回去，但是度量值为无穷大（16跳）。这样可以更明确地告诉邻居“不要通过我走这条路”。
    4. **抑制计时器 (Hold-down Timers)：** 当一条路由被标记为不可达后，路由器会在一段时间内（抑制期）忽略关于这条路由的任何度量值更高的更新。这有助于防止路由在网络稳定前发生振荡。但RIP本身不常用Hold-down，更多见于EIGRP。
    5. **触发更新 (Triggered Updates)：** 如前所述，立即广播网络变化，加速信息传播。

**可能的考法：**

- 描述距离矢量算法的基本工作原理。
- 解释“计数到无穷”问题及其产生原因。
- 详述水平分割和毒性反转如何帮助解决路由环路问题。
- RIP如何确定最佳路径（基于跳数）。
- RIP的更新机制（定期更新和触发更新）。

